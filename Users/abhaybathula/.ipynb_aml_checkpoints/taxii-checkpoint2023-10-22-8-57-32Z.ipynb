{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# only libraries allowed are:\n",
        "# Scikit-learn, XGBoost, Imblearn, NumPy\n",
        "# Pandas, SciPy, Pickle, regex\n",
        "# Seaborn, Matplotlib, Lightgbm\n",
        "\n",
        "from sklearnex import patch_sklearn\n",
        "patch_sklearn()\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
        "from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
        "        \n",
        "XYTrain = pd.read_csv('train.csv')\n",
        "XTest = pd.read_csv('test.csv') # naturally, there is no Y in the testing set\n",
        "\n",
        "def preprocess(df):\n",
        "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
        "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
        "    df['trip_duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).abs().dt.total_seconds()\n",
        "    \n",
        "    df['passenger_count'].fillna(df['passenger_count'].mode()[0], inplace=True)\n",
        "    df['payment_type'].replace('unknown', 'Credit Card', inplace = True)\n",
        "    df['RatecodeID'].fillna(df['RatecodeID'].mode()[0], inplace=True)\n",
        "    df['congestion_surcharge'].fillna(0, inplace=True)\n",
        "    df['store_and_fwd_flag'].fillna('N',inplace=True)\n",
        "    df['Airport_fee'].fillna(0, inplace=True)\n",
        "    \n",
        "    df = pd.get_dummies(df, columns=['store_and_fwd_flag'], prefix=['store_and_fwd_flag'])\n",
        "    df = pd.get_dummies(df, columns=['payment_type'], prefix=['payment_type'])\n",
        "    \n",
        "    df['improvement_surcharge'] = df['improvement_surcharge'].abs()\n",
        "    df['congestion_surcharge'] = df['congestion_surcharge'].abs()\n",
        "    df['tolls_amount'] = df['tolls_amount'].abs()\n",
        "    df['Airport_fee'] = df['Airport_fee'].abs()\n",
        "    df['extra'] = df['extra'].abs()\n",
        "    \n",
        "    #df = df.drop(columns=['VendorID', 'RatecodeID', 'PULocationID', 'DOLocationID'])\n",
        "    \n",
        "    try:\n",
        "        df['total_amount'] = df['total_amount'].abs()\n",
        "        Y = df['total_amount']\n",
        "        df = df.drop(columns=['total_amount', 'tpep_dropoff_datetime', 'tpep_pickup_datetime'])\n",
        "        \n",
        "        numericalCols = [x for x in df.select_dtypes(include = 'number').columns.to_list()] #if 'ID' not in x]\n",
        "        df[numericalCols] = MinMaxScaler().fit_transform(df[numericalCols])\n",
        "        \n",
        "        return train_test_split(df, Y, test_size=0.2, random_state=42)\n",
        "    except:\n",
        "        df = df.drop(columns=['tpep_dropoff_datetime', 'tpep_pickup_datetime'])\n",
        "        \n",
        "        numericalCols = [x for x in df.select_dtypes(include = 'number').columns.to_list()] #if 'ID' not in x]\n",
        "        df[numericalCols] = MinMaxScaler().fit_transform(df[numericalCols])\n",
        "        \n",
        "        return df\n",
        "\n",
        "XTest = preprocess(XTest)\n",
        "XTrain, XVal, YTrain, YVal = preprocess(XYTrain)\n",
        "\n",
        "best_models_raw = {}\n",
        "best_models_tuned = {}"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1700625693720
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline LR Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Pipeline([\n",
        "    ('poly', PolynomialFeatures()),\n",
        "    ('regressor', LinearRegression())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'poly__degree': [2, 3],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "grid_search.fit(XTrain, YTrain)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "YPred = best_model.predict(XVal)\n",
        "print(f'R2 score: {r2_score(YPred, YVal)}')\n",
        "print(f'Best params: {best_params}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "R2 score: 0.8772601173373252\nBest params: {'poly__degree': 2}\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700560207708
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Untuned Run"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressors = {\n",
        "    'Linear Regression': (LinearRegression(), {}),\n",
        "    'K-Nearest Neighbors Regressor': (KNeighborsRegressor(), {}),\n",
        "    'Support Vector Regressor': (SVR(), {}),\n",
        "    'Decision Tree Regressor': (DecisionTreeRegressor(), {}),\n",
        "    'Bagging Regressor': (BaggingRegressor(estimator=DecisionTreeRegressor()), {}),\n",
        "    'AdaBoost Regressor': (AdaBoostRegressor(estimator=DecisionTreeRegressor()), {}),\n",
        "    'Multi-Layer Perceptron Regressor': (MLPRegressor(), {})\n",
        "}\n",
        "\n",
        "for regressor_name, (regressor, param_grid) in regressors.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('poly', PolynomialFeatures(degree=2)),\n",
        "        ('regressor', regressor)\n",
        "    ])\n",
        "    \n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "    grid_search.fit(XTrain, YTrain)\n",
        "    \n",
        "    best_models_raw[regressor_name] = {\n",
        "        'model': grid_search.best_estimator_,\n",
        "        'params': grid_search.best_params_\n",
        "    }\n",
        "    \n",
        "    YPred = grid_search.best_estimator_.predict(XVal)\n",
        "\n",
        "r2_table_raw, i = pd.DataFrame(columns=['Model Name', 'R2 Score on Training','R2 Score on Validation', '% Difference in R2']), 0\n",
        "for regressor_name, results in best_models_raw.items():\n",
        "    YPredVal = results[\"model\"].predict(XVal)\n",
        "    YPredTrn = results[\"model\"].predict(XTrain)\n",
        "    r2_val = r2_score(YPredVal, YVal)\n",
        "    r2_trn = r2_score(YPredTrn, YTrain)\n",
        "    r2_table_raw.loc[i] = [regressor_name, r2_trn, r2_val, abs(r2_trn-r2_val)*100/abs(r2_trn)]\n",
        "    i=i+1"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "LR\tmodel trained with an R-squared scores of 0.8774 on the validation set and 0.8736 on the training set.\nKNN\tmodel trained with an R-squared scores of 0.6824 on the validation set and 0.7921 on the training set.\nCART\tmodel trained with an R-squared scores of 0.9111 on the validation set and 1.0000 on the training set.\nMLP\tmodel trained with an R-squared scores of 0.8109 on the validation set and 0.4096 on the training set.\nBagging\tmodel trained with an R-squared scores of 0.9466 on the validation set and 0.9877 on the training set.\nBoosting\tmodel trained with an R-squared scores of 0.9490 on the validation set and 1.0000 on the training set.\nSVM\tmodel trained with an R-squared scores of -0.1158 on the validation set and -0.1123 on the training set.\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1699766518250
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuned Run"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressors = {\n",
        "    #'Decision Tree Regressor (Tuned)': (DecisionTreeRegressor(), {'regressor__max_depth': [None, 5, 10, 20], 'regressor__ccp_alpha': [0.01, 0.1, 1]}),\n",
        "    #'Bagging Regressor (Tuned)': (BaggingRegressor(estimator=DecisionTreeRegressor()), {'regressor__n_estimators': [10, 50, 100]}),\n",
        "    'AdaBoost Regressor (Tuned)': (AdaBoostRegressor(estimator=DecisionTreeRegressor()), {'regressor__n_estimators': [10, 50, 100], 'regressor__learning_rate': [0.1, 1.0, 2.0], 'regressor__loss': ['linear', 'square', 'exponential']}),\n",
        "}\n",
        "\n",
        "for regressor_name, (regressor, param_grid) in regressors.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('poly', PolynomialFeatures(degree=2)),\n",
        "        ('regressor', regressor)\n",
        "    ])\n",
        "    \n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "    grid_search.fit(XTrain, YTrain)\n",
        "    \n",
        "    best_models_tuned[regressor_name] = {\n",
        "        'model': grid_search.best_estimator_,\n",
        "        'params': grid_search.best_params_\n",
        "    }\n",
        "    \n",
        "\n",
        "r2_table_tuned, i = pd.DataFrame(columns=['Model Name', 'R2 Score on Training','R2 Score on Validation', '% Difference in R2']), 0\n",
        "for regressor_name, results in best_models_tuned.items():\n",
        "    YPredVal = results[\"model\"].predict(XVal)\n",
        "    YPredTrn = results[\"model\"].predict(XTrain)\n",
        "    r2_val = r2_score(YPredVal, YVal)\n",
        "    r2_trn = r2_score(YPredTrn, YTrain)\n",
        "    r2_table_tuned.loc[i] = [regressor_name, r2_trn, r2_val, abs(r2_trn-r2_val)*100/abs(r2_trn)]\n",
        "    i=i+1\n",
        "    \n",
        "r2_table_tuned"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  warnings.warn(\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "                        Model Name  R2 Score on Training  \\\n2  Decision Tree Regressor (Tuned)              0.952982   \n3        Bagging Regressor (Tuned)              0.990570   \n4       AdaBoost Regressor (Tuned)              0.999911   \n\n   R2 Score on Validation  % Difference in R2  \n2                0.926811            2.746227  \n3                0.951213            3.973134  \n4                0.951514            4.840120  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model Name</th>\n      <th>R2 Score on Training</th>\n      <th>R2 Score on Validation</th>\n      <th>% Difference in R2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Decision Tree Regressor (Tuned)</td>\n      <td>0.952982</td>\n      <td>0.926811</td>\n      <td>2.746227</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Bagging Regressor (Tuned)</td>\n      <td>0.990570</td>\n      <td>0.951213</td>\n      <td>3.973134</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AdaBoost Regressor (Tuned)</td>\n      <td>0.999911</td>\n      <td>0.951514</td>\n      <td>4.840120</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700581057561
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_tuned['AdaBoost Regressor (Tuned)']"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "{'model': Pipeline(steps=[('scaler', StandardScaler()), ('poly', PolynomialFeatures()),\n                 ('regressor',\n                  AdaBoostRegressor(estimator=DecisionTreeRegressor(),\n                                    learning_rate=2.0, loss='exponential',\n                                    n_estimators=100))]),\n 'params': {'regressor__learning_rate': 2.0,\n  'regressor__loss': 'exponential',\n  'regressor__n_estimators': 100}}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700582572111
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XTrain = PolynomialFeatures(degree=2).fit_transform(XTrain)\n",
        "\n",
        "final_model = AdaBoostRegressor(estimator=DecisionTreeRegressor(),\n",
        "                          learning_rate=2.0, \n",
        "                          loss='exponential',\n",
        "                          n_estimators=100)\n",
        "\n",
        "final_model.fit(XTrain, YTrain)\n",
        "\n",
        "YPred = final_model.predict(XTest)\n",
        "OUTdf = pd.DataFrame()\n",
        "OUTdf['ID'], OUTdf['total_amount'] = [x for x in range(1, XTest.shape[0]+1)], YPred\n",
        "\n",
        "OUTdf.to_csv('submission.csv', index = False)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1700643381580
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressors = {\n",
        "    'Decision Tree Regressor (Tuned)': (DecisionTreeRegressor(), {'regressor__max_depth': [10], 'regressor__ccp_alpha': [0.01]}),\n",
        "    'Bagging Regressor (Tuned)': (BaggingRegressor(estimator=DecisionTreeRegressor()), {'regressor__n_estimators': [100]}),\n",
        "    'AdaBoost Regressor (Tuned)': (AdaBoostRegressor(estimator=DecisionTreeRegressor()), {'regressor__n_estimators': [100], 'regressor__learning_rate': [2.0], 'regressor__loss': ['exponential']}),\n",
        "}\n",
        "\n",
        "for regressor_name, (regressor, param_grid) in regressors.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('poly', PolynomialFeatures(degree=2)),\n",
        "        ('regressor', regressor)\n",
        "    ])\n",
        "    \n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "    grid_search.fit(XTrain, YTrain)\n",
        "    \n",
        "    best_models_tuned[regressor_name] = {\n",
        "        'model': grid_search.best_estimator_,\n",
        "        'params': grid_search.best_params_\n",
        "    }\n",
        "    \n",
        "\n",
        "r2_table_tuned, i = pd.DataFrame(columns=['Model Name', 'R2 Score on Training','R2 Score on Validation', '% Difference in R2']), 2\n",
        "for regressor_name, results in best_models_tuned.items():\n",
        "    YPredVal = results[\"model\"].predict(XVal)\n",
        "    YPredTrn = results[\"model\"].predict(XTrain)\n",
        "    r2_val = r2_score(YPredVal, YVal)\n",
        "    r2_trn = r2_score(YPredTrn, YTrain)\n",
        "    r2_table_tuned.loc[i] = [regressor_name, r2_trn, r2_val, abs(r2_trn-r2_val)*100/abs(r2_trn)]\n",
        "    i=i+1\n",
        "    \n",
        "r2_table_tuned"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Additional Models"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressors = {\n",
        "    'Decision Tree Regressor (Tuned)': (DecisionTreeRegressor(), {'regressor__max_depth': [None, 5, 10, 20], 'regressor__ccp_alpha': [0.01, 0.1, 1]}),\n",
        "    'Bagging Regressor (Tuned)': (BaggingRegressor(estimator=DecisionTreeRegressor()), {'regressor__n_estimators': [10, 50, 100]}),\n",
        "    'AdaBoost Regressor (Tuned)': (AdaBoostRegressor(estimator=DecisionTreeRegressor()), {'regressor__n_estimators': [10, 50, 100], 'regressor__learning_rate': [0.1, 1.0, 2.0], 'regressor__loss': ['linear', 'square', 'exponential']}),\n",
        "}\n",
        "\n",
        "for regressor_name, (regressor, param_grid) in regressors.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('poly', PolynomialFeatures(degree=2)),\n",
        "        ('regressor', regressor)\n",
        "    ])\n",
        "    \n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
        "    grid_search.fit(XTrain, YTrain)\n",
        "    \n",
        "    best_models_raw[regressor_name] = {\n",
        "        'model': grid_search.best_estimator_,\n",
        "        'params': grid_search.best_params_\n",
        "    }\n",
        "    \n",
        "\n",
        "r2_table_tuned, i = pd.DataFrame(columns=['Model Name', 'R2 Score on Training','R2 Score on Validation', '% Difference in R2']), 0\n",
        "for regressor_name, results in best_models_raw.items():\n",
        "    YPredVal = results[\"model\"].predict(XVal)\n",
        "    YPredTrn = results[\"model\"].predict(XTrain)\n",
        "    r2_val = r2_score(YPredVal, YVal)\n",
        "    r2_trn = r2_score(YPredTrn, YTrain)\n",
        "    r2_table_tuned.loc[i] = [regressor_name, r2_trn, r2_val, abs(r2_trn-r2_val)*100/abs(r2_trn)]\n",
        "    i=i+1\n",
        "    \n",
        "r2_table_tuned"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}